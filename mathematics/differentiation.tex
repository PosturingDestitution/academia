\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\setlength{\parindent}{0pt}

\title{Differentiation}
\author{alexander}
\date{\today}

\begin{document}
\maketitle

\textbf{the derivative} of a function $f$ at $x = a$ is the limit of the difference quotients (if it exists):
\begin{center} $f'(a) = \lim_{h \to 0}\frac{f(a + h) - f(a)}{h}$ \end{center}
when the limit exists, we say that $f$ is differentiable at $x = a$. an equivalent definition of the derivative is
\begin{center} $f'(a) = \lim_{x \to a}\frac{f(x) - f(a)}{x - a}$ \end{center}

\textbf{tangent lines:}\\
assume that $f(x)$ is differentiable at $x = a$. the tangent line to the graph of $y = f(x)$ at $P = (a, f(a))$ is the line through $P$ of slope $f'(a)$. the equation of the tangent line in point-slope form is
\begin{center} $y - f(a) = f'(a)(x - a)$ \end{center}

\textbf{derivative of linear and constant functions:}
	\begin{itemize}
		\item if $f(x) = mx + b$ is a linear function, then $f'(a) = m$ for all $a$
		\item if $f(x) = b$ is a constant function, then $f'(a) = 0$ for all $a$
	\end{itemize}

\textbf{the power rule (1)}
	\begin{enumerate}
		\item $\frac{d}{dx}(x^n) = \lim_{h \to 0}\frac{(x + h)^n - x^n}{h}$
		\item $(x + h)^n = \sum_{k=0}^{n}\binom{n}{k}x^{n-k}h^k$
		\item $(x + h)^n - x^n = \sum_{k=1}^{n}\binom{n}{k}x^{n-k}h^k$ 
		\item $\frac{(x + h)^n - x^n}{h} = \sum_{k=1}^{n}\binom{n}{k}x^{n-k}h^{k-1}$ 
		\item take the limit as $h \to 0$. all terms with $h^{k-1}$ for $k \geq 2$ go to zero. only the $k=1$ term remains.
		\item $\binom{n}{1}x^{n-1} = nx^{n-1}$
		\item $\frac{d}{dx}(x^n) = nx^{n-1}$
	\end{enumerate}

\textbf{the power rule (2)}
	\begin{enumerate}
		\item $f'(a) = \lim_{x \to a}\frac{x^n - a^n}{x - a}$
		\item $x^n - a^n = (x - a)(x^{n-1} + x^{n-2}a + \ldots + xa^{n-2} + a^{n-1})$
		\item $\frac{x^n - a^n}{x - a} = x^{n-1} + x^{n-2}a + \ldots + xa^{n-2} + a^{n-1}$ 
		\item $f'(a) = na^{n-1}$
	\end{enumerate}

\textbf{linearity rules} assume that $f$ and $g$ are differentiable functions
	\begin{itemize}
		\item sum rule: the function $f + g$ is differentiable and $(f + g)' = f' + g'$
		\item constant multiple rule: for any constant $c$, $cf$ is differentiable and $(cf)' = cf'$
	\end{itemize}

\textbf{differentiability implies continuity} 	
	\begin{enumerate}
		\item theorem: if $f$ is differentiable at $c$, then $f$ is continuous at $c$


		\item since $f$ is differentiable at $c$, the limit $f'(c) = \lim_{x \to c}\frac{f(x) - f(c)}{x - c}$ exists


		\item to expose the structure behind this limit, we rewrite the difference quotient as the sum of the tangent slope and a small error term measuring the difference between the secant slope and the tangent slope: $f'(c) + \epsilon(x) = \frac{f(x) - f(c)}{x - c}$ 		


		\item $\epsilon(x) = \frac{f(x) - f(c)}{x - c} - f'(c)$ because the difference quotient tends to $f'(c)$ as $x \to c$, this error term must satisfy $\lim_{x \to c}\epsilon(x) = 0$


		\item this decomposition allows us to express $f(x)$ in a linearized form: $y - y_1 = m(x - x_1) \Rightarrow L(x) = f(c) + f'(c)(x - c) \Rightarrow f(x) = f(c) + f'(c)(x - c) + \epsilon(x)(x - c)$	

		\item this expression shows that near $c$, the function behaves like its tangent line plus an error term. and because $\epsilon(x) \to 0$ and $x - c \to 0$, the product $\epsilon(x)(x - c)$ also goes to 0. thus, $\lim_{x \to c}f(x) = f(c) + 0 + 0 = f(c)$


	\end{enumerate}

\textbf{proof of the product rule}
	\begin{enumerate}
		\item $(fg)'(x) = \lim_{h \to 0}\frac{f(x + h)g(x + h) - f(x)g(x)}{h}$
		\item add and subtract $f(x)g(x + h)$
		\item $\lim_{h \to 0}\frac{f(x + h)g(x + h) - f(x)g(x + h) + f(x)g(x + h) - f(x)g(x)}{h}$
		\item $\lim_{h \to 0}[\frac{f(x + h) - f(x)}{h}g(x + h) + f(x)\frac{g(x + h) - g(x)}{h}]$
		\item $\lim_{h \to 0}\frac{f(x + h) - f(x)}{h} \cdot \lim_{h \to 0}g(x + h) + f(x) \cdot \lim_{h \to 0}\frac{g(x + h) - g(x)}{h}$
		\item $(fg)'x = f'(x)g(x) + f(x)g'(x)$
	\end{enumerate}

\textbf{proof of the quotient rule}
	\begin{enumerate}
		\item $(\frac{f}{g}(x))' = \lim_{h \to 0}\frac{\frac{f(x + h)}{g(x + h)} - \frac{f(x)}{g(x)}}{h}$	
		\item $\frac{f(x + h)}{g(x + h)} - \frac{f(x)}{g(x)} = \frac{f(x + h)g(x) - f(x)g(x + h)}{g(x + h)g(x)}$
		\item $\lim_{h \to 0}\frac{\frac{f(x + h)}{g(x + h)} - \frac{f(x)}{g(x)}}{h} = \lim_{h \to 0}\frac{f(x + h)g(x) - f(x)g(x + h)}{hg(x + h)g(x)}$
		\item add and subtract $f(x)g(x)$
		\item $\lim_{h \to 0}\frac{g(x)(f(x + h) - f(x)) - f(x)(g(x + h) - g(x))}{hg(x + h)g(x)}$
		\item $\lim_{h \to 0}[\frac{f(x + h) - f(x)}{h} \cdot \frac{g(x)}{g(x + h)g(x)} - \frac{g(x + h) - g(x)}{h} \cdot \frac{f(x)}{g(x + h)g(x)}]$
		\item $f'(x) \cdot \frac{1}{g(x)} - g'(x)\frac{f(x)}{g(x)g(x)}$
		\item $\frac{f'(x)}{g(x)} - \frac{f(x)g'(x)}{[g(x)]^2} = \frac{f'(x)g(x) - f(x)g'(x)}{[g(x)]^2}$
	\end{enumerate}

\textbf{proof of the derivative of sin}
	\begin{enumerate}
		\item $\frac{d}{dx}\sin(x) = \lim_{h \to 0}\frac{\sin(x + h) - \sin(x)}{h}$
		\item $\sin(x + h) = \sin(x)\cos(h) + \cos(x)\sin(h)$
		\item $\lim_{h \to 0}\frac{\sin(x + h) - \sin(x)}{h} = \lim_{h \to 0}\frac{\sin(x)\cos(h) - \sin(x) + \cos(x)\sin(h)}{h}$
		\item $\lim_{h \to 0}\frac{\sin(x)(\cos(h) - 1) + \cos(x)\sin(h)}{h}$
		\item $\lim_{h \to 0}[\sin(x) \cdot \frac{\cos(h) - 1}{h} + \cos(x) \cdot \frac{\sin(h)}{h}]$
		\item $\sin(x) \cdot (0) + \cos(x) \cdot (1)$
		\item $\frac{d}{dx}\sin(x) = \cos(x)$
	\end{enumerate}

\textbf{proof of the chain rule}
	\begin{enumerate}
		\item $h(x) = f(g(x))$ 
		\item $h'(x) = \lim_{h \to 0}\frac{f(g(x + h)) - f(g(x))}{h}$
		\item notice that the numerator is $\Delta f$ and the denominator is $\Delta x$ not the change in $\Delta g$
		\item $\frac{f(g(x + h)) - f(g(x))}{1} \cdot \frac{1}{g(x + h) - g(x)} \cdot \frac{1}{h} \cdot \frac{g(x + h) - g(x)}{1}$
		\item $\lim_{h \to 0}\frac{f(g(x + h)) - f(g(x))}{h} = \lim_{h \to 0}\frac{f(g(x + h)) - f(g(x))}{g(x + h) - g(x)} \cdot \lim_{h \to 0}\frac{g(x + h) - g(x)}{h}$
		\item $h'(x) = f'(g(x)) \cdot g'(x)$
	\end{enumerate}

\textbf{implicit differentiation:}\\
to differentiate using the methods covered thus far, we must have a formula for $y$ in terms of $x$, for instance, $y = x^3 + 1$. but suppose that $y$ is determined instead by an equation such as $y^4 + xy = x^3 - x + 2$. in this case, we say that $y$ is defined implicitly. how can we find the slope of the tangent line at a point on the graph? it may be inconvenient or even impossible to solve for $y$ explicitly as a function of $x$, but we can find $\frac{dy}{dx}$ using the method of implicit differentiation. to illustrate, consider the equation of the unit circle:
	\begin{enumerate}
		\item $x^2 + y^2 = 1$
		\item to compute $\frac{dy}{dx}$, first take the derivative of both sides of the equation and evaluate: \\ $\frac{d}{dx}(x^2 + y^2) = \frac{d}{dx}(1)$
		\item $\frac{d}{dx}(x^2) + \frac{d}{dx}(y^2) = 0$
		\item $2x + \frac{d}{dx}(y^2) = 0$
		\item what should we do with the term $\frac{d}{dx}(y^2)$? we use the chain rule. if we think of $y$ as a function $y = f(x)$, then $y^2 = f(x)^2$, and by the chain rule,\\ $\frac{d}{dx}y^2 = \frac{d}{dx}f(x)^2 = 2f(x)\frac{df}{dx} = 2y\frac{dy}{dx}$
		\item $2x + \frac{d}{dx}(y^2)\to 2x + 2y\frac{dy}{dx}$, and we may solve for $\frac{dy}{dx}$ if $y \neq 0$:
		\item $\frac{dy}{dx} = -\frac{x}{y}$
	\end{enumerate}

\textbf{related rates:}\\
in related rate problems, the goal is to calculate an unknown rate of change in terms of other rates of change that are known. one typical problem involves a ladder learning against a wall. the question is: how fast does the ladder move if the bottom of the ladder is pulled away from the wall at constant speed? what is interesting and perhaps surprising is that the top and bottom travel at different speeds.\\

\textbf{linear approximation:}\\
we can use the derivative to estimate $\Delta f$ without computing it exactly. by definition, the derivative is the limit\\ $f'(a) = \lim_{\Delta x \to 0}\frac{f(a + \Delta x) - f(a)}{\Delta x} = \lim_{\Delta x \to 0}\frac{\Delta f}{\Delta x}$\\ so when $\Delta x$ is small, we have $\frac{\Delta f}{\Delta x} \approx f'(a)$, and thus, $\Delta f \approx f'(a)\Delta x$\\

the linear approximation if often called the tangent line approximation because of the following interpretation. the quantitiy $\Delta f$ is the vertical change from $x = a$ to $a = a + \Delta x$ in the graph of $f(x)$. recall that for a nonvertical straight line, the vertical change is equal to the slope times the horizontal change. since the tangent line has slope $f'(a)$ the vertical change in the tangent line is $f'(a)\Delta x$. what the linear approximation does, therefore, is used the vertical change in the tangent line as an approximation to the vertical change in the graph of $f(x)$. when $\Delta x$ is small, the two quantities are nearly equal.\\

Keep in mind the different roles played by $\Delta f$ and $f'(a)\Delta x$. the quantity of interest is $\Delta f$ and we estimate it by $f'(a)\Delta x$. most importantly, the linear approximation tells us that there is a nearly linear relationship between $\Delta f$ and $\Delta x$ when $\Delta x$ is small because differentiability means that the function is locally well-approximated by a line. (differentiability at $a$ means that near $a$, the function behaves almost like its tangent line)\\

\textbf{linearization:}\\
we can approximate $f(x)$ itself rather than the change $\Delta f$ by rewriting the linear approximation in terms of the variable $x = a + \Delta x$. Then\\ $f(a + \Delta x) - f(a) \approx f'(a)\Delta x$\\ $f(x) - f(a) \approx f'(a)(x - a)$ (since $\Delta x = x - a$)\\ $f(x) \approx f(a) + f'(a)(x - a)$\\ the function on the right, denoted by $L(x)$, is called the linearization of $f(x)$ at $x = a$:\\ $L(x) = f'(a)(x - a) + f(a)$\\ we refer to $x = a$ as the center of the linearization. notice that $y = L(x)$ is the equation of the tangent line to the graph of $f(x)$ at $x = a$\\

\textbf{approximating $f(x)$ by its linearization} assume that $f$ is differentiable at $x = a$ if $x$ is close to $a$, then\\ $f(x) \approx L(x) = f'(a)(x - a) + f(a)$\\

\textbf{absolute extrema on an interval}
for $f$ defined on an interval $I$ and $a \in I$:
\begin{itemize}
    \item $f(a)$ is an \emph{absolute minimum} on $I$ if $f(a) \le f(x)$ for all $x \in I$.
    \item $f(a)$ is an \emph{absolute maximum} on $I$ if $f(a) \ge f(x)$ for all $x \in I$.
\end{itemize}

\textbf{extreme value theorem}
If $f$ is continuous on a closed interval $[a,b]$, then $f$ attains both a minimum and a maximum on $[a,b]$.\\

\textbf{local extrema}
$f$ has a
\begin{itemize}
    \item \emph{local minimum} at $c$ if $f(c)$ is the minimum on some open interval containing $c$;
    \item \emph{local maximum} at $c$ if $f(c)$ is the maximum on some open interval containing $c$.
\end{itemize}

\textbf{critical point}
a number $c$ in the domain of $f$ is a critical point if $f'(c)=0$ or $f'(c)$ does not exist.\\

\textbf{fermat's Theorem}
if $f$ has a local extremum at $c$ and $f'(c)$ exists, then $f'(c)=0$.\\

\textbf{locating extrema on $[a,b]$}
if $f$ is continuous on $[a,b]$, then any absolute max/min occurs at a critical point or at an endpoint.\\

\textbf{rolle's theorem}
if $f$ is continuous on $[a,b]$, differentiable on $(a,b)$, and $f(a)=f(b)$, then there exists $c \in (a,b)$ such that $f'(c)=0$.\\

\textbf{mean value theorem}
if $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$, then there exists $c \in (a,b)$ such that
\[
f'(c)=\frac{f(b)-f(a)}{b-a}.
\]

\textbf{sign of the derivative}
For differentiable $f$ on $(a,b)$:
\begin{itemize}
    \item if $f'(x)>0$, then $f$ is increasing on $(a,b)$;
    \item if $f'(x)<0$, then $f$ is decreasing on $(a,b)$.
\end{itemize}

\textbf{first derivative test}
If $c$ is a critical point:
\begin{itemize}
    \item $f'$ changes $+$ to $-$ at $c$ $\implies$ local max.
    \item $f'$ changes $-$ to $+$ at $c$ $\implies$ local min.
\end{itemize}

\textbf{concavity test}
If $f''$ exists on $(a,b)$:
\begin{itemize}
    \item $f''(x)>0$ $\implies$ $f$ is concave up.
    \item $f''(x)<0$ $\implies$ $f$ is concave down.
\end{itemize}

\textbf{test for inflection points}
Suppose $f''$ exists on $(a,b)$ and let $c \in (a,b)$. 
If $f''(c)=0$ and $f''$ changes sign at $c$, then $f$ has an inflection point at $c$.\\

\textbf{second derivative test}
Let $c$ be a critical point and assume $f''(c)$ exists.
\begin{itemize}
    \item $f''(c) > 0 \;\Rightarrow\; f(c)$ is a local minimum.
    \item $f''(c) < 0 \;\Rightarrow\; f(c)$ is a local maximum.
    \item $f''(c) = 0 \;\Rightarrow\;$ test is inconclusive.
\end{itemize}

\textbf{newton's method:}\\
this is a procedure for finding numerical approximations to zeros of functions. numerical approximations are important because it is often impossible to find the zeros exactly. for example, the polynomial $f(x) = x^5 - x - 1$ has one real root $c$, but we can prove, using an advanced branch of mathematics called Galois Theory, that there is no algebraic formula for this root. newtons method shows that $c \approx 1.1673$, and with enough computation, we can compute $c$ to any desired degree of accuracy.\\

in newton's method, we begin by choosing a number $x_0$, which we believe is close to a root of $f(x)$. this starting value $x_0$ is called the initial guess. newton's method then produces a sequence $x_0, x_1, x_2, \ldots$ of successive approximations that, in favorable situations, converge to a root.\\

steps:
	\begin{itemize}
		\item choose initial guess $x_0$ (close to the desired root if possible).
		\item generate successive approximations $x_1, x_2, \ldots$ where\\ $x_{n + 1} = x_n - \frac{f(x_n)}{f'(x_n)}$
	\end{itemize}

\textbf{derivatives:}
	\begin{itemize}
		\item $\frac{d}{dx}(c) = 0$
		\item $\frac{d}{dx}x = 1$
		\item $\frac{d}{dx}(x^n) = nx^{-1}$ (power rule)
		\item $\frac{d}{dx}[cf(x)] = cf'(x)$
		\item $\frac{d}{dx}[f(x)+g(x)] = f'(x) + g'(x)$
		\item $\frac{d}{dx}[f(x)g(x)] = f(x)g'(x) + g(x)f'(x)$
		\item $\frac{d}{dx}[\frac{f(x)}{g(x)}] = \frac{g(x)f'(x) - f(x)g'(x)}{[g(x)]^2}$
		\item $\frac{d}{dx}f(g(x)) = f'(g(x))g'(x)$
		\item $\frac{d}{dx}f(x)^n = nf(x)^{n-1}f'(x)$
		\item $\frac{d}{dx}\sin(x) = \cos(x)$
		\item $\frac{d}{dx}\cos(x) = -\sin(x)$
		\item $\frac{d}{dx}\tan(x) = \sec^2(x)$
		\item $\frac{d}{dx}\csc(x) = -\csc(x)\cot(x)$
		\item $\frac{d}{dx}\sec(x) = \sec(x)\tan(x)$
		\item $\frac{d}{dx}\cot(x) = -\csc^2(x)$
		\item $\frac{d}{dx}\sin^{-1}(x) = \frac{1}{\sqrt(1 - x^2)}$
		\item $\frac{d}{dx}\cos^{-1}(x) = -\frac{1}{\sqrt(1 - x^2)}$
		\item $\frac{d}{dx}\tan^{-1}(x) = \frac{1}{1 + x^2}$
		\item $\frac{d}{dx}(e^x) = e^x$
		\item $\frac{d}{dx}(a^x) = (\ln a)a^x$
		\item $\frac{d}{dx}\ln\mid x\mid = \frac{1}{x}$
		\item $\frac{d}{dx}\log_ax = \frac{1}{(\ln a)x}$
	\end{itemize}

\end{document}
